{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_CLEANING_PROJECT_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overview\n",
    "# format concistency checking\n",
    "# columns, renaming,spliting\n",
    "# wrangling\n",
    "# typecasting\n",
    "# checking duplicates\n",
    "# checking NA's\n",
    "# mini EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=r\"C:\\Users\\ASUS\\Desktop\\python-jupiter\\emps_mock.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(url)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy=data.copy()\n",
    "data_copy.head()\n",
    "data_copy.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"name\"] \n",
    "print(data_copy[\"name\"].isna().sum())\n",
    "# there are 9 NaN values\n",
    "print(data_copy[\"name\"].duplicated().sum())\n",
    "print(data_copy.duplicated().sum())\n",
    "# there are 3 duplicated values in whole table\n",
    "print(data_copy[\"name\"].nunique())\n",
    "# except for the na's and duplicates, we have 91 unique values which means \"name\" column may be our identifier column\n",
    "# object data type: correct\n",
    "# remove duplicates\n",
    "# remove na's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"COUNTRY-CODE\"] \n",
    "print(data_copy[\"COUNTRY-CODE\"].isna().sum())\n",
    "# there are 0 NaN values\n",
    "print(data_copy[\"COUNTRY-CODE\"].nunique())\n",
    "print(data_copy[\"COUNTRY-CODE\"].unique())\n",
    "# there are 15 unique countries\n",
    "# object data type: correct\n",
    "# col name must be converted into snake_case\n",
    "# consistency: okay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"gender\"]\n",
    "print(data_copy[\"gender\"].isna().sum())\n",
    "# there is no null value\n",
    "print(data_copy[\"gender\"].nunique())\n",
    "# there are 7 unique values\n",
    "print(data_copy[\"gender\"].unique())\n",
    "# object data type: correct\n",
    "# consistency: okay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_copy[\"BIRTH-DATE\"].tail(20))\n",
    "# there are format and separator issues, some are M/D/Y some are D.M.Y\n",
    "print(data_copy[\"BIRTH-DATE\"].isna().sum())\n",
    "# no na's\n",
    "# col name must be convert into snake_case\n",
    "# data format consistency bad\n",
    "# data type not object, must be date\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_copy[\"EMPLOYMENT-SPAN\"].head(20))\n",
    "print(data_copy[\"EMPLOYMENT-SPAN\"].isna().sum())\n",
    "# no na's\n",
    "# col name must be convert into snake_case\n",
    "# data format consistency okay\n",
    "# data type not object, must be date or integer\n",
    "# must be splitted into start year and end year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data_copy[\"HOURLY-SALARY\"].head(20))\n",
    "# column name must be converted into snake_case\n",
    "# dtype object wrong, must be float\n",
    "# there are some wrong enterings, some values have currency, since all of the values in euros EUR abbrv. not necessary\n",
    "print(data_copy[\"HOURLY-SALARY\"].isna().sum())\n",
    "# no null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data_copy[\"e_mail\"].head(20))\n",
    "print(data_copy[\"e_mail\"].isna().sum())\n",
    "# no null\n",
    "print(data_copy[\"e_mail\"].nunique())\n",
    "# except the 3 duplicates, all unique\n",
    "# data type object correct\n",
    "# since email addresses must contain \"@\" symbol, lets check if there are any invalid enterings\n",
    "data_copy[~data_copy[\"e_mail\"].str.contains(r\"@\")]\n",
    "# no invalid email entering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addres\n",
    "print(data_copy[\"ADDRESS-CODE\"].tail(20))\n",
    "# data type object correct\n",
    "# format consistency okay\n",
    "print(data_copy[\"ADDRESS-CODE\"].isna().sum())\n",
    "# 12 null values\n",
    "# col name must be converted into snake_case\n",
    "# split into city and postal_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(data_copy[\"department\"].head(20))\n",
    "# data_type object: correct\n",
    "print(data_copy[\"department\"].isna().sum())\n",
    "# no nulls\n",
    "print(data_copy[\"department\"].nunique())\n",
    "print(data_copy[\"department\"].unique())\n",
    "# 5 unique departments\n",
    "# consistency of values okay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remote\n",
    "print(data_copy[\"remote\"].head(20))\n",
    "print(data_copy[\"remote\"].unique())\n",
    "# data type must be boolean\n",
    "# since it contains boolean values for clarity we can change col name into \"is_remote\"\n",
    "# there are different representings of True and False so values inconsistent\n",
    "print(data_copy[\"remote\"].nunique())\n",
    "print(data_copy[\"remote\"].isna().sum())\n",
    "# no nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_copy[\"performance\"].tail(20))\n",
    "print(data_copy[\"performance\"].isna().sum())\n",
    "# there are 9 na's\n",
    "print(data_copy[\"performance\"].nunique())\n",
    "print(data_copy[\"performance\"].unique())\n",
    "# data format consistency issues, ill-entered values\n",
    "# data type wrong, not object, must be integer, in order to do that all na,nan, and string-entered values mutst be cleaned and na and nan's may be reperented by zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming\n",
    "data_copy.rename(columns={\"COUNTRY-CODE\":\"country_code\",\n",
    "                          \"BIRTH-DATE\":\"birth_date\",\n",
    "                          \"EMPLOYMENT-SPAN\":\"employment_span\",\n",
    "                          \"HOURLY-SALARY\":\"hourly_salary\",\n",
    "                          \"ADDRESS-CODE\":\"address_postal_code\",\n",
    "                          \"remote\":\"is_remote\"},inplace=True)\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting\n",
    "\n",
    "data_copy[\"start_year\"]=data_copy[\"employment_span\"].str.split(\"-\").str[0]\n",
    "data_copy[\"end_year\"]=data_copy[\"employment_span\"].str.split(\"-\").str[1]\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"city\"]=data_copy[\"address_postal_code\"].str.split(\"-\").str[0]\n",
    "data_copy[\"postal_code\"]=data_copy[\"address_postal_code\"].str.split(\"-\").str[1]\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing unnecessary columns\n",
    "data_copy.drop(columns=[\"employment_span\",\"address_postal_code\"],inplace=True)\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we want to examine employees and have their birth_date, lets add \"age\" column,but first we need to clean that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_copy[\"birth_date\"].tail(20))\n",
    "print(type(data_copy[\"birth_date\"][83]))\n",
    "print(type(data_copy[\"birth_date\"][84]))\n",
    "print(type(data_copy[\"birth_date\"][99]))\n",
    "# we want them in MM-DD-YYYY format\n",
    "#data_copy[\"birth_date\"] = \n",
    "data_copy[\"birth_date\"]=data_copy[\"birth_date\"].astype(str).apply(lambda x: x.replace(\"/\", \"-\").replace(\".\", \"-\") if not x.isdigit() else x)\n",
    "\n",
    "print(data_copy[\"birth_date\"].tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"birth_date\"]=data_copy[\"birth_date\"].astype(str).apply(\n",
    "    lambda x: f\"{x.split('-')[1].zfill(2)}-{x.split('-')[0].zfill(2)}-{x.split(\"-\")[2]}\" \n",
    "    if x.isdigit() == False else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortcut for last 2 cell operations;\n",
    "# print(data_copy[\"birth_date\"].astype(str).apply(lambda x: pd.to_datetime(x,format=\"mixed\") if x.isdigit()==False else x).tail(20))\n",
    "# with this, you dont have to arrange and wrangle and clean any m-d-y or m/d/y or d.y.m format!!!! it detects everyone of of them and converts Y-m-d automatically !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"birth_date\"]=data_copy[\"birth_date\"].apply(\n",
    "    lambda x: pd.to_datetime('1900-01-01') + pd.to_timedelta(int(x), unit='D') if x.isdigit()==True else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"birth_date\"]=data_copy[\"birth_date\"].apply(\n",
    "    lambda x: pd.to_datetime(x,format=\"mixed\") if isinstance(x,str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"birth_date\"].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"age\"]=data_copy[\"birth_date\"].apply(lambda x:pd.Timestamp.now().year-x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "# since we have cleaned birth_date in order to calculate ages, lets continue cleaning from hourly_salary\n",
    "# the hourly_salary columns have some values that consist currency and we dont need that since we know all the values is in euros already\n",
    "print(type(data_copy[\"hourly_salary\"][0]))\n",
    "print(type(data_copy[\"hourly_salary\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[data_copy[\"hourly_salary\"].str.contains(r\"[^\\d.,]\", regex=True)]\n",
    "# \\d digit, . and , ^ do not include\n",
    "# since all of the representings of currency are in the end of the values, we can split them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"hourly_salary\"]=data_copy[\"hourly_salary\"].str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_remote\n",
    "print(data_copy[\"is_remote\"].unique())\n",
    "# is_remote column has different values for boolean type values e.g. True is represented by both  T  yes YES and y so we should wrangle this\n",
    "data_copy[\"is_remote\"]=data_copy[\"is_remote\"].replace({\"Y\":True,\"yes\":True,\"T\":True,\"y\":True,\"YES\":True,\"No\":False,\"F\":False,\"no\":False,\"f\":False,\"NO\":False,})\n",
    "print(data_copy[\"is_remote\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance\n",
    "print(data_copy[\"performance\"].tail(20))\n",
    "# we have NaN's, na's and unnecessary characters like .,+,* and we want to turn Nan's and na's into zeros and get rid of unnecessary characters\n",
    "\n",
    "data_copy[~data_copy[\"performance\"].astype(str).str.match(r\"^-?\\d+$\", na=False)].shape[0]\n",
    "data_copy[\"performance\"][~data_copy[\"performance\"].astype(str).str.match(r\"^-?\\d+$\", na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"performance\"].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_copy[\"performance\"].isna().sum())\n",
    "# there are 9 NaN entered values but as we can see there are na and Na entered values, according to python those are strings\n",
    "data_copy[\"performance\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"performance\"].isna().head(20)\n",
    "data_copy[\"performance\"].head(20)\n",
    "print(data_copy[\"performance\"][15])\n",
    "print(data_copy[\"performance\"][18])\n",
    "print(type(data_copy[\"performance\"][15]))\n",
    "print(type(data_copy[\"performance\"][18]))\n",
    "print(type(str(data_copy[\"performance\"][15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, if the first character is .lower()==\"n\" then replace it with 0.\n",
    "data_copy[\"performance\"][(data_copy[\"performance\"].astype(str).str[0].str.lower()==\"n\")].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"performance\"][(data_copy[\"performance\"].astype(str).str[0].str.lower()==\"n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"performance\"]=data_copy[\"performance\"].apply(lambda x: 0 if str(x)[0].lower()==\"n\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_copy[\"performance\"].isna().sum())\n",
    "print((data_copy[\"performance\"].astype(str).str[0].str.lower()==\"n\").sum())\n",
    "print(data_copy[\"performance\"].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, lets get rid of . * and +\n",
    "data_copy[\"performance\"][data_copy[\"performance\"].astype(str).str.contains(r\"[^-\\d]\",regex=True)].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(data_copy[\"performance\"].astype(str).str.contains(r\"[^-\\d]\",regex=True)==True,\"\",data_copy[\"performance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"original\": data_copy[\"performance\"].tail(20),\n",
    "    \"cleaned\": data_copy[\"performance\"].astype(str).str.replace(r\"[^-\\d]\", \"\", regex=True).tail(20)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"performance\"]=data_copy[\"performance\"].astype(str).str.replace(r\"[^-\\d]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_year checking\n",
    "print(data_copy[\"start_year\"].isna().sum())\n",
    "print(data_copy[\"start_year\"].unique())\n",
    "# must be len()==4\n",
    "data_copy[data_copy[\"start_year\"].str.len() != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_year checking\n",
    "print(data_copy[\"end_year\"].isna().sum())\n",
    "print(data_copy[\"end_year\"].unique())\n",
    "# must be len()==4\n",
    "data_copy[data_copy[\"end_year\"].str.len() != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_year must be >= start_year\n",
    "data_copy[data_copy[\"start_year\"]>data_copy[\"end_year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city checking\n",
    "print(data_copy[\"city\"].isna().sum())\n",
    "print(data_copy[\"city\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postal_code checking\n",
    "# must be len()==5\n",
    "print(data_copy[\"postal_code\"].isna().sum())\n",
    "data_copy[data_copy[\"postal_code\"].astype(str).str.len() != 5]\n",
    "# there is one invalid postal code we should turn that into NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"postal_code\"]=data_copy[\"postal_code\"].astype(str).apply(lambda x: pd.NA if len(str(x)) != 5 else x)\n",
    "# also we have dealt with this columns na's too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[\"postal_code\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age checking \n",
    "# must be in between 0 and 100\n",
    "data_copy[\"age\"].head(20)\n",
    "data_copy[\"age\"].isna().sum()\n",
    "data_copy[\"age\"].nunique()\n",
    "data_copy[\"age\"].unique()\n",
    "data_copy[(data_copy[\"age\"].astype(int)<=0) | (data_copy[\"age\"].astype(int)>=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type converting\n",
    "data_copy.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly_salary--float,performance--int,start_year & end_year--int\n",
    "# whenever we do typecasting, always check nan's\n",
    "print(data_copy[\"hourly_salary\"].isna().sum())\n",
    "print(data_copy[\"performance\"].isna().sum())\n",
    "print(data_copy[\"start_year\"].isna().sum())\n",
    "print(data_copy[\"end_year\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy[[\"hourly_salary\", \"performance\", \"start_year\", \"end_year\"]] = data_copy[[\"hourly_salary\", \"performance\", \"start_year\", \"end_year\"]].astype({\n",
    "    \"hourly_salary\": \"float\",\n",
    "    \"performance\": \"int\",\n",
    "    \"start_year\": \"int\",\n",
    "    \"end_year\": \"int\"\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing duplicates\n",
    "# we know there were 3 duplicates,\n",
    "data_copy.duplicated().sum()\n",
    "data_copy[data_copy.duplicated()]\n",
    "data_copy.drop_duplicates().shape[0]\n",
    "data_copy=data_copy.drop_duplicates()\n",
    "data_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking/populating NaN's\n",
    "data_copy.isna().sum()\n",
    "data_copy[data_copy[\"name\"].isna()]\n",
    "# since this table is about employees and we dont have an identifier column more likely than name column, i think we should drop that rows that are NA in name column\n",
    "data_copy.dropna(subset=[\"name\"]).shape\n",
    "data_copy=data_copy.dropna(subset=[\"name\"])\n",
    "data_copy.shape\n",
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# of course after dropping na's our index is become like this\n",
    "data_copy.index\n",
    "# so;\n",
    "data_copy.reset_index(inplace=True,drop=True)\n",
    "data_copy.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean _data extracting\n",
    "cleaned_data=data_copy.copy()\n",
    "cleaned_data.head(20)\n",
    "#clean_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv(\"cleaned_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eda\n",
    "# how many employees in each country\n",
    "\n",
    "cleaned_data.groupby(\"country_code\")[\"name\"].count().to_frame(\"emp_count_by_countries\").sort_values(\"emp_count_by_countries\",ascending=False).reset_index()\n",
    "# our employees are mostly from Denmark, Spain, Ireland and Italy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employees department distribution\n",
    "cleaned_data.groupby(\"department\")[\"name\"].count().to_frame(\"emps_by_department\").sort_values(\"emps_by_department\",ascending=False).reset_index()\n",
    "# the most crowded department of our company's is HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many employees in each gender\n",
    "cleaned_data.groupby(\"gender\")[\"name\"].count().to_frame(\"emp_count_by_gender\").sort_values(\"emp_count_by_gender\",ascending=False).reset_index()\n",
    "# our employees identify themselves mostly as male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# employees age distribution \n",
    "age_summary=pd.DataFrame({\"oldest\":[cleaned_data[\"age\"].max()],\"average\":[cleaned_data[\"age\"].mean()],\"youngest\":[cleaned_data[\"age\"].min()]})\n",
    "age_summary\n",
    "# our company is young"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# department salary average\n",
    "cleaned_data.groupby(\"department\")[\"hourly_salary\"].mean().to_frame(\"avg_salary_by_departments\").sort_values(\"avg_salary_by_departments\",ascending=False).reset_index()\n",
    "# although our most crowded department is HR, employees that are in marketing department earns the highest salaries by average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# department performance average\n",
    "cleaned_data.groupby(\"department\")[\"performance\"].mean().to_frame(\"avg_performance_rate_by_departments\").sort_values(\"avg_performance_rate_by_departments\",ascending=False).reset_index()\n",
    "# although the customer service departmend has the lowest average pay, the department is our company's the most effective department\n",
    "# although our most crowded department is HR, performance rate average in that department is relatively low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THANK YOU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
